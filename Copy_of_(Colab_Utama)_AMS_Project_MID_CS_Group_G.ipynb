{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadizza/AMS-MID-CS-GROUP-G/blob/main/Copy_of_(Colab_Utama)_AMS_Project_MID_CS_Group_G.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Capstone Project Analisis Media Sosial - Group G***\n",
        "\n",
        "| NIM | Nama | Deskripsi |\n",
        "| -------- | -------- | -------- |\n",
        "|1122094000006  |AHMAD IZZA |Ambil Data, Preprocessing, Visualisasi |\n",
        "|11220940000047  |RAJWAA WARDA YUNENDA PUTRI |Ambil Data,Visualisasi, PPT |\n",
        "|11220940000063   |AWALIA DAMAYANTI  |Ambil Data, Visualisasi, PPT, Video |\n",
        "|11220940000073  |NIKEN SAFIRA |Ambil Data, Visualisasi |\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5A8EBk-KCrdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latar Belakang"
      ],
      "metadata": {
        "id": "jtIjkGKERMPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada bulan Mei 2025, program barak militer bagi siswa bermasalah di Jawa Barat yang digagas oleh Dedi Mulyadi menjadi perbincangan hangat di ruang publik. Program ini bertujuan membina kedisiplinan dan karakter siswa yang dianggap memiliki perilaku menyimpang melalui pendekatan militeristik.\n",
        "\n",
        "Meskipun dinilai sebagai langkah tegas untuk mengatasi kenakalan remaja, program ini menimbulkan pro dan kontra. Sebagian masyarakat mendukungnya sebagai solusi konkret terhadap masalah perilaku siswa, sementara yang lain mengkritiknya karena dianggap terlalu keras dan berpotensi melanggar hak anak.\n",
        "\n",
        "Diskusi mengenai program ini ramai terjadi di media sosial, khususnya YouTube, yang menjadi wadah bagi masyarakat untuk mengekspresikan opini mereka. Analisis sentimen terhadap percakapan ini dapat memberikan gambaran mengenai persepsi publik, serta menjadi masukan penting bagi pembuat kebijakan dalam menangani siswa bermasalah secara lebih bijak dan manusiawi."
      ],
      "metadata": {
        "id": "qhViEg9ZRVJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rumusan Masalah"
      ],
      "metadata": {
        "id": "G5Zz8rVBRdDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Permasalahan**\n",
        "\n",
        "1. Apa isu-isu utama yang muncul terkait program barak militer bagi siswa bermasalah di Jawa Barat?\n",
        "\n",
        "2. Bagaimana sentimen publik terhadap program barak militer bagi siswa bermasalah?\n",
        "\n",
        "3. Bagaimana pola percakapan warganet tentang program ini di media sosial, khususnya YouTube?\n",
        "\n",
        "4. Bagaimana respons warganet terhadap sosok Dedi Mulyadi sebagai penggagas program tersebut?\n"
      ],
      "metadata": {
        "id": "0F9CeONBRfwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Periode Pengumpulan Data**\n",
        "\n",
        "2 Mei-27 Mei 2025"
      ],
      "metadata": {
        "id": "5OZELrhPRw_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sumber Data**\n",
        "\n",
        "YouTube"
      ],
      "metadata": {
        "id": "8Z8hybNDR86P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kata Kunci**\n",
        "* Program barak militer\n",
        "* Barak Militer Dedi Mulyadi\n",
        "* Barak militer anak\n",
        "* Barak militer siswa\n",
        "* Siswa nakal Jawa barat\n"
      ],
      "metadata": {
        "id": "8NywKV0pSD5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "5SWDY4JCCj5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sastrawi\n",
        "!pip install emoji # Install the emoji library\n",
        "!pip install textblob\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import emoji\n",
        "\n",
        "nltk.download('popular')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "rQ8OyV6Da9fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mempersiapkan Data**"
      ],
      "metadata": {
        "id": "v-h0yuO7seKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pengambilan Data YouTube"
      ],
      "metadata": {
        "id": "GHspZAng3RQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah mengambil data di YouTube lalu kami lakukan proses penggabungan dan duplikat agar satu keyword mengambil video yang berbeda dari yang lain.\n",
        "\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Mencari semua file CSV di dalam folder 'tweets-data'\n",
        "csv_files = glob.glob('tweets-data/*.csv') # list nama file yang disimpan\n",
        "csv_files.sort()  # Use the sort() method of the list object\n",
        "\n",
        "n = 0\n",
        "for filename in csv_files: ## Menggabungkan file csv dalam bentuk dataframe\n",
        "  # Read the CSV file into a pandas DataFrame\n",
        "  if n == 0:\n",
        "    df = pd.read_csv(filename, delimiter=\",\")\n",
        "    n = 1\n",
        "  else:\n",
        "    df2 = pd.read_csv(filename, delimiter=\",\")\n",
        "    df = pd.concat([df, df2])\n",
        "    n+=1\n",
        "\n",
        "# Membuang duplikat berdasarkan id_str\n",
        "df.drop_duplicates(subset=['id_str'], keep='first', inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Ekspor Data Hasil Scrapping\n",
        "from google.colab import files\n",
        "namafile = \"DATAX_Naturalisasi_fix.csv\"\n",
        "df.to_csv(namafile, index=False)\n",
        "files.download(namafile)\n",
        "\"Exported\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QmEfBtjv_E5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kami menggunakan 5 keyword dan melakukan proses pengambilan komentar di video youtobe secara acak menggunakan API\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Pengambilan yang kami lakukan\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import googleapiclient.discovery\n",
        "\n",
        "api_key = \"your-api-key\"\n",
        "\n",
        "keywords = [\n",
        "    \"Program barak militer\",\n",
        "    \"Barak Militer Dedi Mulyadi\",\n",
        "    \"Barak militer anak\",\n",
        "    \"Barak militer siswa\",\n",
        "    \"Siswa nakal Jawa barat\"\n",
        "]\n",
        "\n",
        "used_video_ids = set()  # Untuk menyimpan video yang sudah dipakai\n",
        "\n",
        "def search_and_get_comments(search_query, max_videos=10, max_comments_per_video=250, start_date=None, end_date=None, csv_filename=\"youtube_comments.csv\"):\n",
        "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "\n",
        "    search_response = youtube.search().list(\n",
        "        part=\"snippet\",\n",
        "        q=search_query,\n",
        "        type=\"video\",\n",
        "        maxResults=30  # ambil lebih banyak untuk jaga-jaga (nanti kita filter jadi 10 unik)\n",
        "    ).execute()\n",
        "\n",
        "    # Filter video yang belum dipakai\n",
        "    video_titles_and_ids = {}\n",
        "    for item in search_response['items']:\n",
        "        if item['id']['kind'] == 'youtube#video':\n",
        "            video_id = item['id']['videoId']\n",
        "            if video_id not in used_video_ids:\n",
        "                video_titles_and_ids[video_id] = item['snippet']['title']\n",
        "                if len(video_titles_and_ids) >= max_videos:\n",
        "                    break\n",
        "\n",
        "    used_video_ids.update(video_titles_and_ids.keys())  # Tandai video ini sudah terpakai\n",
        "\n",
        "    if not video_titles_and_ids:\n",
        "        print(f\"No new videos found for keyword '{search_query}'. Skipping.\")\n",
        "        return\n",
        "\n",
        "    total_comments = 0\n",
        "    unique_comments = set()\n",
        "\n",
        "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\") if start_date else None\n",
        "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\") if end_date else None\n",
        "\n",
        "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"keyword\", \"video_id\", \"video_title\", \"comment_text\", \"published_at\"])  # Header\n",
        "\n",
        "        for video_id, video_title in video_titles_and_ids.items():\n",
        "            try:\n",
        "                next_page_token = None\n",
        "                comments_written = 0\n",
        "\n",
        "                while True:\n",
        "                    request = youtube.commentThreads().list(\n",
        "                        part=\"snippet\",\n",
        "                        videoId=video_id,\n",
        "                        maxResults=100,\n",
        "                        pageToken=next_page_token\n",
        "                    )\n",
        "                    response = request.execute()\n",
        "\n",
        "                    for item in response['items']:\n",
        "                        try:\n",
        "                            snippet = item['snippet']['topLevelComment']['snippet']\n",
        "                            comment_text = snippet['textDisplay']\n",
        "                            published_at = snippet['publishedAt']\n",
        "                            comment_dt = datetime.strptime(published_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "\n",
        "                            if (start_dt and comment_dt < start_dt) or (end_dt and comment_dt > end_dt):\n",
        "                                continue\n",
        "\n",
        "                            unique_id = f\"{video_id}_{comment_text}\"\n",
        "                            if unique_id in unique_comments:\n",
        "                                continue\n",
        "                            unique_comments.add(unique_id)\n",
        "\n",
        "                            writer.writerow([search_query, video_id, video_title, comment_text, published_at])\n",
        "                            total_comments += 1\n",
        "                            comments_written += 1\n",
        "\n",
        "                            if comments_written >= max_comments_per_video:\n",
        "                                break\n",
        "                        except KeyError:\n",
        "                            continue\n",
        "\n",
        "                    next_page_token = response.get(\"nextPageToken\")\n",
        "                    if not next_page_token or comments_written >= max_comments_per_video:\n",
        "                        break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error retrieving comments for video ID {video_id}: {e}\")\n",
        "\n",
        "    print(f\"CSV file '{csv_filename}' created for keyword '{search_query}'.\")\n",
        "    print(f\"Total unique comments retrieved: {total_comments}\")\n",
        "    print(f\"Number of videos fetched: {len(video_titles_and_ids)}\")\n",
        "\n",
        "# Run for all keywords\n",
        "start_date = \"2025-05-02\"\n",
        "end_date = \"2025-05-28\"\n",
        "\n",
        "for keyword in keywords:\n",
        "    csv_file = f\"youtube_comments_{keyword.replace(' ', '_')}.csv\"\n",
        "    search_and_get_comments(keyword, max_videos=10, max_comments_per_video=250, start_date=start_date, end_date=end_date, csv_filename=csv_file)\n",
        "\n",
        "     \n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qEJh2lr-ALp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "mROpqQFhCpPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut Link hasil pengambilan data dari youtobe:\n",
        "- https://raw.githubusercontent.com/ahmadizza/AMS-MID-CS-GROUP-G/main/all_youtube_comments_combined.csv\n"
      ],
      "metadata": {
        "id": "wcxlYqpNBZIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data hasil pengambilan dari youtobe\n",
        "import pandas as pd\n",
        "\n",
        "# URL file raw CSV dari GitHub\n",
        "url = 'https://raw.githubusercontent.com/ahmadizza/AMS-MID-CS-GROUP-G/main/all_youtube_comments_combined.csv'\n",
        "\n",
        "# Membaca file langsung dari URL\n",
        "dataRaw = pd.read_csv(url, low_memory=False, encoding='utf8')\n",
        "\n",
        "# Menampilkan beberapa baris pertama\n",
        "dataRaw.head()"
      ],
      "metadata": {
        "id": "zCtkwbXcOi4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# melihat kolom di dataRaw\n",
        "dataRaw.columns"
      ],
      "metadata": {
        "id": "Zu7w9jEMjAYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "MZSL6UxACulY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Duplikasi Data"
      ],
      "metadata": {
        "id": "gRiI-UQ_eonR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan domment text yang duplikat\n",
        "duplicate_count = dataRaw.duplicated(subset='comment_text').sum()\n",
        "print(f\"Jumlah komentar duplikat: {duplicate_count}\")"
      ],
      "metadata": {
        "id": "ii0yV0LIesOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan contoh komentar duplikat dalam bentuk tabel\n",
        "dataRaw[dataRaw.duplicated(subset='comment_text', keep=False)].head(86)"
      ],
      "metadata": {
        "id": "7XVAmygcewNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghapus Duplikat\n",
        "dataRaw.drop_duplicates(subset='comment_text', inplace=True)"
      ],
      "metadata": {
        "id": "epDnbapVezdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek kembali yang Duplikat\n",
        "duplicate_count = dataRaw.duplicated(subset='comment_text').sum()\n",
        "print(f\"Jumlah komentar duplikat: {duplicate_count}\")"
      ],
      "metadata": {
        "id": "D5swIvk0e360"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan dalam bentuk CSV untuk data tanpa komen yanng duplikat\n",
        "# dataRaw.to_csv('comments_no_duplicates.csv', index=False)"
      ],
      "metadata": {
        "id": "6PV6VuYWfCGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Menambahkan labelling ke dalam Dataset"
      ],
      "metadata": {
        "id": "CrkKcwCIfnQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari data komentar tanpa duplikat, dilanjutkan dengan labelling dan disimpan di link github berikut :\n",
        "\n",
        "https://raw.githubusercontent.com/ahmadizza/AMS-MID-CS-GROUP-G/refs/heads/main/youtube_comments_labeling_no%20duplicates_no%20comment%20judol.csv\n",
        "\n",
        "\n",
        "\n",
        "Kami telah melakukan proses pelabelan sentimen (1:Positif, 2:Netral, dan 3:Negatif) pada setiap tweet sebelum data ini diunggah ke GitHub dan diimpor ke sini. Langkah ini dilakukan untuk mendukung analisis sentimen publik terkait topik Persepsi Publik di Media Sosial terhadap Program Barak Militer bagi Siswa Bermasalah di Jawa Barat."
      ],
      "metadata": {
        "id": "b9XFHfkkfdFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url2 = \"https://raw.githubusercontent.com/ahmadizza/AMS-MID-CS-GROUP-G/refs/heads/main/youtube_comments_labeling_no%20duplicates_no%20comment%20judol.csv\"\n",
        "data = pd.read_csv(url2, low_memory=False, encoding='utf8')\n",
        "data"
      ],
      "metadata": {
        "id": "1iqj3g7hglPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop kolom yang tidak diperlukan\n",
        "data = data.drop(columns=['keyword', 'video_id'])\n",
        "# Ubah urutan kolom: published_at di awal, sisanya diikuti\n",
        "cols = ['published_at', 'video_title', 'comment_text', 'label']\n",
        "data = data[cols]\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "_hMVFkBJgheK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ubah Tipe Data"
      ],
      "metadata": {
        "id": "Eo826rdli4bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek tipe data\n",
        "data.info()"
      ],
      "metadata": {
        "id": "VqnN0aB2jEsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ubah 'label' menjadi kategori\n",
        "data['label'] = data['label'].astype('category')\n",
        "\n",
        "# Ubah 'published_at' menjadi datetime (format ISO 8601 ke waktu biasa)\n",
        "data['published_at'] = pd.to_datetime(data['published_at'], format='%Y-%m-%dT%H:%M:%SZ')\n",
        "\n",
        "# Cek hasil\n",
        "data.dtypes"
      ],
      "metadata": {
        "id": "0iFtTGqFjJIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek jumlah tiap label\n",
        "data['label'].value_counts()"
      ],
      "metadata": {
        "id": "hLLzqenHjRXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Value"
      ],
      "metadata": {
        "id": "z9Yny-qZjXZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek Missing Value\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "MXqjoS3ijZO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena tidak ada missing value maka tidak perlu dihapus dan tidak perlu diubah apa apa datanya"
      ],
      "metadata": {
        "id": "z8U6sAZFje_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cleaning Text**"
      ],
      "metadata": {
        "id": "su943ggEjtgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membersihkan teks dari URL, mention, emoji, hashtag, angka, tanda baca, dan spasi berlebih\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Ubah ke lowercase\n",
        "\n",
        "    # Hilangkan karakter aneh (emoji, simbol asing)\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "\n",
        "    # Hapus URL, mention, hashtag\n",
        "    text = re.sub(r'http\\S+|www.\\S+', '', text)       # URL\n",
        "    text = re.sub(r'@\\w+', '', text)                  # mention\n",
        "    text = emoji.replace_emoji(text, replace='')\n",
        "    text = re.sub(r'#\\w+', '', text)                  # hashtag\n",
        "\n",
        "    # Hapus angka\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Hapus tanda baca\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Hapus spasi berlebih\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "0HlHmtYHj5N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membersihkan semua teks dalam kolom comment_text\n",
        "data['cleaned_text'] = data['comment_text'].apply(clean_text)\n",
        "data"
      ],
      "metadata": {
        "id": "ya3e2IK2j9r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalisasi Data"
      ],
      "metadata": {
        "id": "4XeOZNrTkbTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat folder data\n",
        "!mkdir -p data\n",
        "!wget -P data/ https://raw.githubusercontent.com/ahmadizza/AMS-MID-CS-GROUP-G/refs/heads/main/slangs%20%26%20typos.txt\n",
        "\n",
        "# Lokasi file\n",
        "slang_file = 'data/slangs & typos.txt'\n",
        "\n",
        "# Membuat kamus slang dari file\n",
        "slang_dict = {}\n",
        "with open(slang_file, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        if ':' in line:\n",
        "            slang, standard = line.strip().split(':', 1)\n",
        "            slang_dict[slang.strip()] = standard.strip()\n",
        "\n",
        "# Pastikan sudah import word_tokenize (dari NLTK)\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Fungsi untuk mengganti slang dengan kata baku\n",
        "def normalize_slang(text):\n",
        "    words = word_tokenize(text.lower())\n",
        "    return ' '.join([slang_dict.get(word, word) for word in words])\n",
        "\n",
        "# Terapkan ke kolom 'cleaned_text'\n",
        "data['normalized_comment'] = data['cleaned_text'].apply(normalize_slang)\n",
        "\n",
        "# Lihat hasil\n",
        "data[['cleaned_text', 'normalized_comment']].head()"
      ],
      "metadata": {
        "id": "X_80kAr2kqVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek isi data\n",
        "data"
      ],
      "metadata": {
        "id": "VvTlNhYXkqcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Data Lanjutan"
      ],
      "metadata": {
        "id": "3VZ63t8KlLo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membersihkan semua teks dalam kolom normalized_comment\n",
        "data['cleaned_text2'] = data['normalized_comment'].apply(clean_text)\n",
        "data"
      ],
      "metadata": {
        "id": "7Zgytmk6kqjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stopword"
      ],
      "metadata": {
        "id": "kM-9XfrDlT2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebelumnya kita sudah gabungkan semua stopword menjadi satu file dalam link berikut :\n",
        "\n",
        "https://raw.githubusercontent.com/ahmadizza/AMS-MID-CS-GROUP-G/refs/heads/main/stopwords.txt"
      ],
      "metadata": {
        "id": "ZBzSSQNdlcXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O data/stopwords_id.txt https://raw.githubusercontent.com/ahmadizza/AMS-MID-CS-GROUP-G/refs/heads/main/stopwords.txt\n",
        "# Menghapus stopwords bahasa Indonesia\n",
        "# Baca file stopwords\n",
        "with open('data/stopwords_id.txt', \"r\", encoding=\"utf-8\", errors='replace') as file:\n",
        "    id_stop = file.readlines()\n",
        "\n",
        "# Bersihkan stopwords (strip newline/spasi & lowercase)\n",
        "id_stop = [word.strip().lower() for word in id_stop]\n",
        "\n",
        "# Tambahkan kata-kata tambahan\n",
        "additional_stopwords = {\n",
        "    'nya', 'iya', 'itu', 'kah', 'dan', 'ke', 'di',\n",
        "    'turun', 'naik', 'ambil', 'lihat',\n",
        "    'tolong', 'atas', 'pokok', 'hari',\n",
        "    'naikin', 'presiden', 'indonesia', 'sih', 'pakai',\n",
        "    'biar', 'juta', 'ribu',\n",
        "}\n",
        "\n",
        "# Gabungkan ke list utama\n",
        "id_stop = set(id_stop).union(additional_stopwords)\n",
        "\n",
        "# Fungsi hapus stopwords\n",
        "def remove_custom_stopwords(text):\n",
        "    words = word_tokenize(text)\n",
        "    return ' '.join([word for word in words if word not in id_stop])\n",
        "\n",
        "# Terapkan ke kolom yang sudah dibersihkan sebelumnya\n",
        "data['no_stopwords'] = data['cleaned_text2'].apply(remove_custom_stopwords)\n",
        "\n",
        "# Lihat hasil\n",
        "data"
      ],
      "metadata": {
        "id": "bnFme_JhlanU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Lemmatization"
      ],
      "metadata": {
        "id": "sAHPnNGkmdyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Proses mengubah kata ke bentuk dasarnya (root word).\n",
        "# Inisialisasi stemmer Sastrawi\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# Fungsi stemming menggunakan Sastrawi\n",
        "def stem_text(text):\n",
        "    return stemmer.stem(text)\n",
        "\n",
        "# Terapkan stemming pada kolom 'no_stopwords'\n",
        "data['stemmed_text'] = data['no_stopwords'].apply(stem_text)\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "SUFNOR2HmjLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stopword lanjutan"
      ],
      "metadata": {
        "id": "DZMxW1YGmmAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Kode untuk Top 100 Kata dari df_stemmed ---\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "all_words = []\n",
        "\n",
        "# Iterasi melalui setiap entri di kolom 'stemmed_text'\n",
        "# Menggunakan .dropna() untuk menghindari error jika ada nilai NaN\n",
        "# Menggunakan .astype(str) untuk mengubah semua nilai menjadi string (mengantisipasi jika ada tipe data lain)\n",
        "for text_entry in data['stemmed_text'].dropna().astype(str):\n",
        "    if text_entry.strip():  # Memastikan string tidak kosong setelah di-strip\n",
        "        # Jika isi 'stemmed_text' adalah string kata-kata yang dipisahkan spasi\n",
        "        words = text_entry.split()\n",
        "        all_words.extend(words)\n",
        "        # Jika isi 'stemmed_text' sudah berupa list of words, Anda bisa langsung:\n",
        "        # all_words.extend(text_entry) # Namun, ini memerlukan text_entry sudah pasti list\n",
        "\n",
        "# Hitung frekuensi setiap kata\n",
        "word_counts = Counter(all_words)\n",
        "\n",
        "# Dapatkan 100 kata paling umum\n",
        "top_100_words = word_counts.most_common(100)\n",
        "\n",
        "print(\"--- Top 100 kata yang sering muncul dari 'stemmed_text' ---\")\n",
        "if top_100_words:\n",
        "    for word, count in top_100_words:\n",
        "        print(f\"{word}: {count}\")\n",
        "else:\n",
        "    print(\"Tidak ada kata untuk dihitung (mungkin semua entri kosong atau NaN).\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "ubHsF0NPmwo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tambahkan stopwords tambahan\n",
        "additional_stopwords = {\n",
        "    'adik', 'agama', 'ajar', 'ala', 'amp', 'anak', 'anggota', 'anggar', 'antem', 'apa', 'arti', 'asasi', 'bantu',\n",
        "    'bawa', 'beda', 'bicara', 'bikin', 'bilang', 'bina', 'bukti', 'cari', 'coba', 'contoh', 'daerah', 'dewan',\n",
        "    'diam', 'didik', 'disiplin', 'dukung', 'gaji buta', 'generasi', 'generasi muda', 'gubenur', 'hak', 'hasil',\n",
        "    'henti', 'hormat', 'ide', 'ikut', 'jakarta', 'jalan', 'jaman', 'jabatan', 'jabat', 'kak seto', 'kali',\n",
        "    'karakter', 'keluarga', 'kerja', 'kaya', 'kirim', 'khofifah', 'komentar', 'komisi', 'koruptor', 'lindung',\n",
        "    'lihat', 'lembaga', 'lulus', 'langsung', 'malu', 'makan', 'makan gaji', 'manusia', 'masuk', 'masyarakat',\n",
        "    'media', 'metropolitan', 'metropolitan televisi', 'mental', 'moga', 'mu', 'muda', 'murid', 'nama', 'nasional',\n",
        "    'neng', 'negara', 'nilai', 'nol', 'nyata', 'omong', 'omon', 'omon omon', 'ono', 'otak', 'pas', 'penuh',\n",
        "    'pikir', 'pilih', 'pimpin', 'pintar', 'republik', 'remaja', 'rg', 'rakyat', 'rumah', 'sila', 'sehat', 'sekolah',\n",
        "    'sesuaI', 'si', 'smp', 'solusi', 'swt', 'tanggung', 'televisi', 'teman', 'tentara', 'teori', 'tinggal', 'timur',\n",
        "    'tuju', 'tujuan', 'tuju', 'ubah', 'uang', 'umpat', 'umpat umpat', 'urus', 'wakil', 'wajib', 'warga', 'wudele',\n",
        "    'nama', 'rocky'\n",
        "}\n",
        "\n",
        "# Gabungkan dengan stopwords yang sudah ada\n",
        "id_stop = set(id_stop).union(additional_stopwords)\n",
        "\n",
        "# Fungsi hapus stopwords dari list kata\n",
        "def remove_custom_stopwords(text):\n",
        "    words = word_tokenize(text)\n",
        "    return ' '.join([word for word in words if word not in id_stop])\n",
        "\n",
        "# Terapkan ke kolom hasil lemmatization (yang sudah berupa list kata)\n",
        "data['no_stopwords2'] = data['stemmed_text'].apply(remove_custom_stopwords)\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "n2xWfxy2m2lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Kode untuk Top 100 Kata dari df_stemmed ---\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "all_words = []\n",
        "\n",
        "# Iterasi melalui setiap entri di kolom 'stemmed_text'\n",
        "# Menggunakan .dropna() untuk menghindari error jika ada nilai NaN\n",
        "# Menggunakan .astype(str) untuk mengubah semua nilai menjadi string (mengantisipasi jika ada tipe data lain)\n",
        "for text_entry in data['no_stopwords2'].dropna().astype(str):\n",
        "    if text_entry.strip():  # Memastikan string tidak kosong setelah di-strip\n",
        "        # Jika isi 'stemmed_text' adalah string kata-kata yang dipisahkan spasi\n",
        "        words = text_entry.split()\n",
        "        all_words.extend(words)\n",
        "        # Jika isi 'stemmed_text' sudah berupa list of words, Anda bisa langsung:\n",
        "        # all_words.extend(text_entry) # Namun, ini memerlukan text_entry sudah pasti list\n",
        "\n",
        "# Hitung frekuensi setiap kata\n",
        "word_counts = Counter(all_words)\n",
        "\n",
        "# Dapatkan 100 kata paling umum\n",
        "top_100_words = word_counts.most_common(100)\n",
        "\n",
        "print(\"--- Top 100 kata yang sering muncul dari 'stemmed_text' ---\")\n",
        "if top_100_words:\n",
        "    for word, count in top_100_words:\n",
        "        print(f\"{word}: {count}\")\n",
        "else:\n",
        "    print(\"Tidak ada kata untuk dihitung (mungkin semua entri kosong atau NaN).\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "5AgkQORLm7mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenisasi"
      ],
      "metadata": {
        "id": "kTf9-Tmxmqkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Proses memecah teks menjadi bagian-bagian kecil yang disebut token. Token biasanya berupa kata, frasa, atau simbol.\n",
        "# Fungsi untuk tokenisasi teks\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)  # Tokenisasi teks menjadi list kata\n",
        "\n",
        "# Terapkan tokenisasi ke kolom 'stemmed_text'\n",
        "data['tokenize_text'] = data['no_stopwords2'].apply(tokenize_text)\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "EmK39LzAnOhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ekspor Data Clean"
      ],
      "metadata": {
        "id": "5gBQoObE2hel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan ke CSV (opsional)\n",
        "# data.to_csv('final_preprocessed_text_Full.csv', index=False)"
      ],
      "metadata": {
        "id": "QLQyv7lZEee3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data diekspor dan akan diunggah ke GitHub untuk memudahkan proses visualisasi, sehingga tidak perlu menjalankan ulang seluruh proses dari data mentah."
      ],
      "metadata": {
        "id": "oY9zE6Qz2tpf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualisasi dan Interpretasi\n"
      ],
      "metadata": {
        "id": "eAJN9FLM_YwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Data Clean**"
      ],
      "metadata": {
        "id": "Lo4GMVx6_lF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut link github setelah di lakukan cleaning dari data mentah:\n",
        "\n",
        "https://raw.githubusercontent.com/ahmadizza/AMS-MID-CS-GROUP-G/refs/heads/main/final_preprocessed_text_full.csv\n",
        "\n",
        "\n",
        "**Import data yang telah di ekspor**\n",
        "import pandas as pd\n",
        "\n",
        "file_ = 'data/data_final_all_fix.csv'\n",
        "try: #Loading Locally\n",
        "    df_final = pd.read_csv(file_)\n",
        "except Exception as err_:\n",
        "    print(err_,\" Trying to load data from GitHub.\")\n",
        "    !mkdir data\n",
        "    !wget -P data/ https://raw.githubusercontent.com/ahmadizza/AMS-MID-CS-GROUP-G/refs/heads/main/final_preprocessed_text_full.csv\n",
        "    df_final = pd.read_csv(file_)\n",
        "\n",
        "print(df_final.shape)\n",
        "df_final.sample(10)"
      ],
      "metadata": {
        "id": "X5CLkXjgoNDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = data"
      ],
      "metadata": {
        "id": "aQKGULtf4oye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jumlah Tweet\n",
        "print(\"Jumlah komen yang kami peroleh:\", df_final.shape[0],\"komen\")"
      ],
      "metadata": {
        "id": "5spxmFtF9cgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.info()"
      ],
      "metadata": {
        "id": "mud-Gk0h_7p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghapus kolom yang tidak digunakan\n",
        "# df_final = df_final.drop(columns=['cleaned_text', 'normalized_comment', 'cleaned_text2', 'no_stopwords', 'stemmed_text','no_stopwords2'])\n",
        "\n",
        "# Mapping angka ke label sentimen\n",
        "sentiment_mapping = {1: 'Positif', 2: 'Netral', 3: 'Negatif'}\n",
        "\n",
        "# Menambahkan kolom label sentimen berdasarkan mapping\n",
        "df_final['sentiment_label'] = df_final['label'].map(sentiment_mapping)\n",
        "\n",
        "# Mengonversi kolom 'published_at' ke format datetime\n",
        "df_final['published_at'] = pd.to_datetime(df_final['published_at'], format='%Y-%m-%d %H:%M:%S')"
      ],
      "metadata": {
        "id": "q-kBqw4F_XZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengurutkan data berdasarkan Waktu\n",
        "df_final = df_final.sort_values(by='published_at')\n",
        "df_final.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "7jyoJwaGTaYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jumlah Komen Harian"
      ],
      "metadata": {
        "id": "haAgUI9CTHp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyiapkan kolom untuk format tanggal harian\n",
        "df_final['tanggal'] = df_final['published_at'].dt.strftime('%d %b')\n",
        "# Menghitung banyak tweet perhari\n",
        "komen_per_hari = df_final.groupby('tanggal').size()\n",
        "# Convert the result into a DataFrame and rename the column\n",
        "komen_per_hari = komen_per_hari.reset_index(name='size')"
      ],
      "metadata": {
        "id": "7XLQIl5ETGic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a figure with one axis\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Barplot\n",
        "sns.barplot(x='tanggal', y='size', data=komen_per_hari, ax=ax, color='salmon')\n",
        "\n",
        "# Lineplot on top of the barplot\n",
        "sns.lineplot(x='tanggal', y='size', data=komen_per_hari, ax=ax, color='red', marker='o')\n",
        "\n",
        "# Annotate the bars\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{int(p.get_height())}',  # Menghapus desimal dan mengubah ke integer\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='bottom',  # Posisikan tepat di atas bar\n",
        "                fontsize=8, color='black',  # Ukuran font lebih kecil\n",
        "                xytext=(0, 5), textcoords='offset points')  # Jarak sedikit di atas bar\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Tanggal')\n",
        "ax.set_ylabel('Jumlah Komen')\n",
        "ax.set_title('Barplot dan Lineplot Jumlah Komen per Hari')\n",
        "\n",
        "# Display the plot\n",
        "plt.xticks(rotation=45)  # Rotate the x-axis labels for better visibility\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oU6aTuUQTqOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretasi:\n",
        "\n",
        "- Isu Program Barak Militer bagi Siswa Bermasalah di Jawa Barat mulai ramai dibicarakan di media sosial pada awal Mei, terutama setelah pernyataan publik dari Dedi Mulyadi.\n",
        "\n",
        "- Lonjakan komentar pertama terjadi pada 4 Mei (549 komen), diduga dipicu oleh pernyataan awal atau viralnya wacana program tersebut di media sosial.\n",
        "\n",
        "- Lonjakan kedua muncul pada 23 Mei (627 komen), kemungkinan sebagai respons terhadap klarifikasi, kritik lanjutan, atau diskusi publik yang kembali mengemuka.\n",
        "\n",
        "- Di antara dua puncak tersebut, terjadi penurunan drastis, mencerminkan redanya diskusi sementara sebelum kembali meningkat — menunjukkan bahwa isu ini memicu kontroversi dan reaksi berulang dari publik."
      ],
      "metadata": {
        "id": "CQyk4CSEUF0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribusi Sentimen per Tanggal"
      ],
      "metadata": {
        "id": "EVxbl64QUE3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pastikan kolom tanggal dalam format datetime dan hanya menyimpan Y-M-D\n",
        "data['published_at'] = pd.to_datetime(data['published_at']).dt.date\n",
        "\n",
        "# Kelompokkan berdasarkan tanggal dan label\n",
        "sentimen_per_tanggal = data.groupby(['published_at', 'label']).size().reset_index(name='jumlah')\n",
        "\n",
        "# Buat bar chart\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.barplot(x='published_at', y='jumlah', hue='label', data=sentimen_per_tanggal, palette='pastel')\n",
        "\n",
        "plt.title(\"Distribusi Sentimen per Tanggal\")\n",
        "plt.xlabel(\"Tanggal\")\n",
        "plt.ylabel(\"Jumlah Sentimen\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Label Sentimen', labels=['Positif (1)', 'Netral (2)', 'Negatif (3)'])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V_hxbBQ8kQSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Persepsi Netizen Pada 1 Bulan Pertama Pemberlakuan Program Barak Militer**\n",
        "\n",
        "Pada minggu pertama, komentar bernada positif paling banyak ditemukan, meskipun tetap ada komentar negatif yang umumnya mengungkapkan kekhawatiran terhadap pendekatan militer yang dianggap terlalu keras dalam membentuk karakter siswa.\n",
        "\n",
        "Memasuki minggu kedua, jumlah total komentar menurun dibandingkan minggu sebelumnya, kemungkinan karena program sedang berlangsung dan perhatian publik mulai menurun. Namun, komentar positif dan netral masih menjadi mayoritas.\n",
        "\n",
        "Pada minggu ketiga dan keempat, jumlah komentar kembali meningkat signifikan, dengan puncaknya terjadi di minggu keempat. Pada periode ini, komentar netral menjadi yang paling dominan. Komentar-komentar tersebut umumnya berisi saran untuk perbaikan program, evaluasi, hingga kritik atau sindiran terhadap pihak pemerintah yang tidak mendukung program dan dianggap ingin menghentikannya.\n",
        "\n",
        "Insight :\n",
        "1. Netralitas dalam opini publik tidak selalu berarti pasif; justru bisa menjadi ekspresi aktif dari partisipasi kritis.\n",
        "\n",
        "  Komentar netral yang dominan di minggu ketiga dan keempat ternyata bukan sekadar “diam” atau “tidak memihak”, melainkan berfungsi sebagai saluran kritik, saran, hingga satire terhadap pihak yang pro maupun kontra. Ini menunjukkan bahwa publik menggunakan ruang netral bukan karena tidak punya pendapat, tetapi sebagai media diskusi, kontrol sosial, dan refleksi kebijakan.\n",
        "\n",
        "2. Isu sentimen negatif bersifat preventif, lebih berupa kewaspadaan terhadap pendekatan kebijakan, bukan perlawanan terhadap tujuannya. Ini memberi peluang bagi pemerintah untuk membangun narasi kebijakan yang lebih edukatif dan empatik.\n",
        "\n",
        "  Komentar negatif di awal bukan sepenuhnya berisi penolakan, melainkan sebagian besar muncul dari kekhawatiran terhadap metode militerisasi dan dampaknya terhadap perkembangan karakter anak.\n",
        "\n"
      ],
      "metadata": {
        "id": "EWKhT5WuNwJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 10 Video dengan Komentar Terbanyak (04 Mei 2025)"
      ],
      "metadata": {
        "id": "4PZoRr_RUJr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data pada tanggal tertentu\n",
        "top_dates2 = ['2025-05-04']\n",
        "data_top2 = data[data['published_at'].isin(pd.to_datetime(top_dates2).date)]\n",
        "\n",
        "# Hitung jumlah komentar per video title\n",
        "video_counts = data_top2['video_title'].value_counts().reset_index()\n",
        "video_counts.columns = ['video_title', 'jumlah_komentar']\n",
        "\n",
        "# Ambil 10 teratas dan urutkan\n",
        "top_n = 10\n",
        "video_counts = video_counts.head(top_n).sort_values(by='jumlah_komentar', ascending=True)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=video_counts, x='jumlah_komentar', y='video_title', palette='viridis')\n",
        "\n",
        "plt.title('Top 10 Video dengan Komentar Terbanyak (4 Mei 2025)', fontsize=14)\n",
        "plt.xlabel('Jumlah Komentar')\n",
        "plt.ylabel('Judul Video')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hCPV4LNsZgfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretasi:\n",
        "\n",
        "Lonjakan pertama terjadi pada tanggal 04 Mei 2025, dengan total 549. Lonjakan pertama terjadi tak lama setelah pemberlakuan Program Barak Militer Bagi Siswa Bermasalah, yang mana menimbulkan berbagai reaksi dari warganet.\n",
        "\n",
        "Sebagian besar judul video yang tampil mengandung kata-kata kontreversi dan emosial, sepeti: \"Anak Nakal\", \"Barak Militer\", \"Momen\", \"Dedi Mulyadi\", \"Sindir Elite\", \"Pro/kontra\". Judul-judul ini berpicu \"clickbait\" sehingga membuat rasa penasaran masyarakat untuk memberi kritik, terutama yang melibatkan emosi. Judul-judul ini juga provokatif dan mengandung isu sosial yang juga cenderung meningkatkan warganet untuk berkomentar"
      ],
      "metadata": {
        "id": "N5S8H5VQDi6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 10 Video dengan Komentar Terbanyak (24 Mei 2025)"
      ],
      "metadata": {
        "id": "XftotjY3UQWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Filter data pada tanggal tertentu\n",
        "top_dates2 = ['2025-05-24']\n",
        "data_top2 = data[data['published_at'].isin(pd.to_datetime(top_dates2).date)]\n",
        "\n",
        "# Hitung jumlah komentar per video title\n",
        "video_counts = data_top2['video_title'].value_counts().reset_index()\n",
        "video_counts.columns = ['video_title', 'jumlah_komentar']\n",
        "\n",
        "# Ambil 10 teratas dan urutkan\n",
        "top_n = 10\n",
        "video_counts = video_counts.head(top_n).sort_values(by='jumlah_komentar', ascending=True)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=video_counts, x='jumlah_komentar', y='video_title', palette='viridis')\n",
        "\n",
        "plt.title('Top 10 Video dengan Komentar Terbanyak (24 Mei 2025)', fontsize=14)\n",
        "plt.xlabel('Jumlah Komentar')\n",
        "plt.ylabel('Judul Video')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8-C8wXFvgizO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intepretasi:\n",
        "\n",
        "Setelah lonjakan awal pada 04 Mei 2025 (549 komentar), lonjakan kedua terjadi pada 24 Mei 2025, dengan total 627 komentar — bahkan lebih tinggi dari sebelumnya.\n",
        "\n",
        "Lonjakan kemungkinan terjadi karena:\n",
        "*   Klarifikasi atau pernyataan publik dari tokoh seperti Dedi Mulyadi, pejabat, atau tokoh pendidikan.\n",
        "*   Konten balasan atau debat lanjutan yang mengangkat kembali isu pendidikan militer.\n",
        "*   Media atau influencer yang kembali menyoroti topik ini, terkhusus di youtube.\n",
        "\n",
        "Judul video dan narasi pun semakin provokatif. Beberapa judul video menggunakan narasi emosional, seperti: \"MERINDING...\", “SETUJUKAH KALIAN DENGAN PROGRAM…”, “Balas Kritikan Pedas…”, “Anak Nakal Jadi Baik…”. Ini menunjukkan tidak meradanya perdebatan warganet, tetapi semakin memanas. Pemilik konten menggunakan judul yang memancing engagement lebih tinggi (clickbait).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FgS8XEyaDmpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analisis Sentimen"
      ],
      "metadata": {
        "id": "fcegjD62SP6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pie chart sentimen"
      ],
      "metadata": {
        "id": "bWv4iNxAZZiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung distribusi kategori\n",
        "category_counts = data['sentiment_label'].value_counts()\n",
        "\n",
        "# Membuat pie chart\n",
        "category_counts.plot.pie(autopct='%1.1f%%', colors=['lightgreen', 'skyblue', 'lightcoral'])\n",
        "\n",
        "# Menambahkan judul\n",
        "plt.title('Distribusi Kategori')\n",
        "\n",
        "# Menampilkan chart\n",
        "plt.ylabel('')  # Menghilangkan label y agar lebih rapi\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AvdJ7CxUZFt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretasi:\n",
        "\n",
        "Netral (53.5%) :\n",
        "\n",
        "- Mayoritas komentar bersifat informasi ulang atau netral secara emosi.\n",
        "\n",
        "- Banyak publik menyampaikan kritik atau pertanyaan ke pemerintah, tanpa menyatakan setuju atau tidak.\n",
        "\n",
        "- Netralitas juga muncul karena publik masih menunggu kejelasan aturan dan pelaksanaan program.\n",
        "\n",
        "Positif (44.5%)\n",
        "\n",
        "- Program dianggap sebagai solusi untuk membentuk kedisiplinan siswa bermasalah.\n",
        "\n",
        "- Banyak yang mendukung upaya tegas dalam menangani geng motor remaja.\n",
        "\n",
        "- Publik berharap barak militer dapat menanamkan nilai-nilai positif dan tanggung jawab.\n",
        "\n",
        "Negatif (2.0%)\n",
        "\n",
        "- Ada anggapan bahwa pendekatan militer bisa memicu perlawanan, bukan perbaikan.\n",
        "\n",
        "- Kekhawatiran bahwa siswa bermasalah malah bisa menjadi lebih keras atau membangkang.\n",
        "\n",
        "- Beberapa menganggap program ini hanya solusi jangka pendek yang tidak menyentuh akar masalah.\n",
        "\n"
      ],
      "metadata": {
        "id": "8c7KkF1PU4rn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentimen Positif"
      ],
      "metadata": {
        "id": "27A1hNYfD0w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pastikan df_stemmed memiliki kolom 'text'\n",
        "# Ambil daftar teks (kalimat) dan ubah ke lowercase\n",
        "texts = data[data['label'] == 1]['no_stopwords2'].astype(str).str.lower().tolist()\n",
        "\n",
        "# Gunakan CountVectorizer untuk ekstraksi bigram\n",
        "vectorizer = CountVectorizer(ngram_range=(2, 2), min_df=2)  # hanya bigram yang muncul minimal 2x\n",
        "X = vectorizer.fit_transform(texts)\n",
        "bigrams = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Pisahkan setiap bigram menjadi pasangan kata\n",
        "edges = [tuple(b.split()) for b in bigrams]\n",
        "\n",
        "# Buat Graph dari bigram\n",
        "G = nx.Graph()\n",
        "G.add_edges_from(edges)\n",
        "\n",
        "# Visualisasi graf bigram\n",
        "plt.figure(figsize=(14, 10))\n",
        "pos = nx.spring_layout(G, k=0.5, seed=42)  # layout posisi node\n",
        "nx.draw(\n",
        "    G, pos,\n",
        "    with_labels=True,\n",
        "    node_color='lightblue',\n",
        "    edge_color='gray',\n",
        "    node_size=1000,\n",
        "    font_size=10,\n",
        "    font_weight='bold'\n",
        ")\n",
        "plt.title(\"Word Link (Bigram Network) dari Teks yang Sudah Distem\", fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cvpui3KyDvSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Network ini menunjukkan bahwa percakapan publik mengenai program barak militer bagi siswa bermasalah mencakup berbagai topik: dari pendidikan, kedisiplinan, hingga kekhawatiran terhadap pendekatan militer. Kata-kata yang saling terhubung menegaskan adanya dua kutub persepsi utama: dukungan karena alasan pembinaan, dan penolakan karena kekhawatiran dampak negatif bagi anak-anak."
      ],
      "metadata": {
        "id": "9cwu-oVKOR-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek kata apa yang paling banyak punya edge (koneksi).\n",
        "import networkx as nx\n",
        "\n",
        "centrality = nx.degree_centrality(G)\n",
        "sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:10]"
      ],
      "metadata": {
        "id": "jZX3ET2ZEL8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter data ke label positif\n",
        "positif_data = data[data['label'] == 1]\n",
        "\n",
        "# Gabungkan semua token menjadi satu list\n",
        "all_tokens = positif_data['tokenize_text'].sum()  # karena isinya list per baris\n",
        "\n",
        "# Ubah list token menjadi string dipisahkan spasi\n",
        "text_positif = \" \".join(all_tokens)\n",
        "\n",
        "# Buat Word Cloud\n",
        "wordcloud = WordCloud(\n",
        "    width=800,\n",
        "    height=400,\n",
        "    background_color='white',\n",
        "    max_words=200,\n",
        "    colormap='YlGnBu'\n",
        ").generate(text_positif)\n",
        "\n",
        "# Tampilkan\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title(\"Word Cloud dari Token untuk Komentar Positif\", fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TxQGtpb_EMsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Makna kata:\n",
        "1. Kata-kata seperti bagus, maju, bijak, mantap, positif, dan hebat menunjukkan dukungan kuat dari sebagian netizen terhadap program pendidikan barak militer.\n",
        "2. Bangga dan cinta menunjukkan adanya emosi  dan keterikatan terhadap program atau sosok tertentu (kemungkinan besar terhadap tokoh seperti Dedi Mulyadi).\n",
        "3. Kata amin memperlihatkan bahwa komentar bersentimen positif sering kali dibumbui dengan doa atau harapan keberhasilan.\n",
        "\n",
        "Word Link:\n",
        "*   Node besar seperti “bangga”, “cinta”, “bijak”, dan “positif” memiliki banyak koneksi, artinya kata ini sering digunakan bersamaan dengan kata-kata bermakna dukungan.\n",
        "*    kata nasionalisme, perintah, pengaruh, senjata, taruna, dan pramuka, menunjukkan danya dukungan terhadap nilai kedisiplinan dan bela negara.\n",
        "\n"
      ],
      "metadata": {
        "id": "owd2PzXGEWIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentimen Negatif"
      ],
      "metadata": {
        "id": "Mvq7YOShEaif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pastikan df_stemmed memiliki kolom 'text'\n",
        "# Ambil daftar teks (kalimat) dan ubah ke lowercase\n",
        "texts = data[data['label'] == 3]['no_stopwords2'].astype(str).str.lower().tolist()\n",
        "\n",
        "# Gunakan CountVectorizer untuk ekstraksi bigram\n",
        "vectorizer = CountVectorizer(ngram_range=(2, 2), min_df=2)  # hanya bigram yang muncul minimal 2x\n",
        "X = vectorizer.fit_transform(texts)\n",
        "bigrams = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Pisahkan setiap bigram menjadi pasangan kata\n",
        "edges = [tuple(b.split()) for b in bigrams]\n",
        "\n",
        "# Buat Graph dari bigram\n",
        "G = nx.Graph()\n",
        "G.add_edges_from(edges)\n",
        "\n",
        "# Visualisasi graf bigram\n",
        "plt.figure(figsize=(14, 10))\n",
        "pos = nx.spring_layout(G, k=0.5, seed=42)  # layout posisi node\n",
        "nx.draw(\n",
        "    G, pos,\n",
        "    with_labels=True,\n",
        "    node_color='lightblue',\n",
        "    edge_color='gray',\n",
        "    node_size=1000,\n",
        "    font_size=10,\n",
        "    font_weight='bold'\n",
        ")\n",
        "plt.title(\"Word Link (Bigram Network) dari Teks yang Sudah Distem\", fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i5lMK0b1Eev2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jaringan ini menunjukkan bahwa persepsi publik mengaitkan program militerisasi siswa dengan isu ideologi (komunisme, perang dingin), otoritarianisme (China), dan alternatif seperti pesantren. Ini mencerminkan keberagaman persepsi, dari kritik ideologis hingga tawaran solusi."
      ],
      "metadata": {
        "id": "2ZsmfE6zQHF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek kata apa yang paling banyak punya edge (koneksi).\n",
        "import networkx as nx\n",
        "\n",
        "centrality = nx.degree_centrality(G)\n",
        "sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:10]"
      ],
      "metadata": {
        "id": "PehJN0_SEe9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter data ke label positif\n",
        "positif_data = data[data['label'] == 3]\n",
        "\n",
        "# Gabungkan semua token menjadi satu list\n",
        "all_tokens = positif_data['tokenize_text'].sum()  # karena isinya list per baris\n",
        "\n",
        "# Ubah list token menjadi string dipisahkan spasi\n",
        "text_positif = \" \".join(all_tokens)\n",
        "\n",
        "# Buat Word Cloud\n",
        "wordcloud = WordCloud(\n",
        "    width=800,\n",
        "    height=400,\n",
        "    background_color='white',\n",
        "    max_words=200,\n",
        "    colormap='YlGnBu'\n",
        ").generate(text_positif)\n",
        "\n",
        "# Tampilkan\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title(\"Word Cloud dari Token untuk Komentar Negatif\", fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cmIqVBesEfDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Makna Kata:\n",
        "1. Kata “pesantren”, “pondok”, dan “psikologi” muncul paling banyak, menunjukkan adanya komentar negatif dengan membandingkannya dengan pendidikan pesantren dan psikologi.\n",
        "2. Kata “gaya”, “keras”, “arogan”, “otoriter”, dan “komunis” menunjukkan persepsi bahwa program militer ini dianggap terlalu kasar, kolot, atau bahkan otoriter.\n",
        "3. Kata “soviet”, “china”, dan “perang dingin” menunjukkan bahwa sebagian warganet menganggap program ini menyerupai sistem pendidikan otoriter dari negara-negara komunis atau zaman Perang Dingin.\n",
        "4. Kata “butuh”, “stigma”, “kosong”, dan “dangkai” menunjukkan kritik bahwa program ini dibuat hanya solusi dangkal.\n",
        "\n",
        "Word Link:\n",
        "- Node \"gaya\" memiliki degree centrality tertinggi, menunukkan mungkin bahwa program militer terkesan gaya yang negatif (kuno atau kaku).\n",
        "- Kata “china” dan “otoriter” terhubung langsung, menunjukkan bahwa program ini dianggap meniru sistem pendidikan negara otoriter.\n",
        "- “Pondok – pesantren” muncul sebagai pasangan (bigram), menunjukkan banyak warganet membandingkan dengan pendidikan pesantren\n",
        "\n"
      ],
      "metadata": {
        "id": "9htE_APHTpsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentimen Netral"
      ],
      "metadata": {
        "id": "g84bPmXrEtg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pastikan df_stemmed memiliki kolom 'text'\n",
        "# Ambil daftar teks (kalimat) dan ubah ke lowercase\n",
        "texts = data[data['label'] == 2]['no_stopwords2'].astype(str).str.lower().tolist()\n",
        "\n",
        "# Gunakan CountVectorizer untuk ekstraksi bigram\n",
        "vectorizer = CountVectorizer(ngram_range=(2, 2), min_df=2)  # hanya bigram yang muncul minimal 2x\n",
        "X = vectorizer.fit_transform(texts)\n",
        "bigrams = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Pisahkan setiap bigram menjadi pasangan kata\n",
        "edges = [tuple(b.split()) for b in bigrams]\n",
        "\n",
        "# Buat Graph dari bigram\n",
        "G = nx.Graph()\n",
        "G.add_edges_from(edges)\n",
        "\n",
        "# Visualisasi graf bigram\n",
        "plt.figure(figsize=(14, 10))\n",
        "pos = nx.spring_layout(G, k=0.5, seed=42)  # layout posisi node\n",
        "nx.draw(\n",
        "    G, pos,\n",
        "    with_labels=True,\n",
        "    node_color='lightblue',\n",
        "    edge_color='gray',\n",
        "    node_size=1000,\n",
        "    font_size=10,\n",
        "    font_weight='bold'\n",
        ")\n",
        "plt.title(\"Word Link (Bigram Network) dari Teks yang Sudah Distem\", fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bKbxZsJjEvpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Narasi publik yang beragam dan padat, mencakup moral anak muda, peran agama, isu kebijakan, hingga media digital.\n",
        "\n",
        "- Moralitas dan agama muncul sebagai nilai dominan dalam merespons isu yang dibahas.\n",
        "\n",
        "- Ada juga nuansa kritik sosial dan politik, serta sorotan terhadap media dan ekspresi daring."
      ],
      "metadata": {
        "id": "lnvVSAwSQldw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter data ke label positif\n",
        "positif_data = data[data['label'] == 2]\n",
        "\n",
        "# Gabungkan semua token menjadi satu list\n",
        "all_tokens = positif_data['tokenize_text'].sum()  # karena isinya list per baris\n",
        "\n",
        "# Ubah list token menjadi string dipisahkan spasi\n",
        "text_positif = \" \".join(all_tokens)\n",
        "\n",
        "# Buat Word Cloud\n",
        "wordcloud = WordCloud(\n",
        "    width=800,\n",
        "    height=400,\n",
        "    background_color='white',\n",
        "    max_words=200,\n",
        "    colormap='YlGnBu'\n",
        ").generate(text_positif)\n",
        "\n",
        "# Tampilkan\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title(\"Word Cloud dari Token untuk Komentar Netral\", fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_57NjLHKEzFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena sentimen netral susah diintrepetasikan, karena dalam konteks topik ini (barak militer untuk siswa nakal), sentimen netral sulit untuk diinterpretasikan atau tidak terlalu bermakna secara analitis. Maka dilakukan analisis lanjutan untuk sentimen netral. (dibawah ini)"
      ],
      "metadata": {
        "id": "yHJapNi2E7R0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analisis Lebih Lanjut Sentimen Netral"
      ],
      "metadata": {
        "id": "nKEvU8MBFBp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Misal kolom sentimen bernama 'label'\n",
        "netral_data = data[data['label'] == 2]\n",
        "print(f\"Total komentar netral: {len(netral_data)}\")"
      ],
      "metadata": {
        "id": "W0Olpl50FGRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Gabungkan semua teks komentar netral\n",
        "all_text = ' '.join(netral_data['no_stopwords2'])\n",
        "\n",
        "# Pecah jadi kata\n",
        "words = all_text.split()\n",
        "word_freq = Counter(words).most_common(20)\n",
        "\n",
        "# Visualisasi\n",
        "import matplotlib.pyplot as plt\n",
        "words, freqs = zip(*word_freq)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.barh(words[::-1], freqs[::-1], color='slategray')\n",
        "plt.title('20 Kata Paling Sering di Komentar Netral')\n",
        "plt.xlabel('Frekuensi')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gk9Gu6I-FIS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Kata-kata seperti bubar, kritik, nyinyir, salah, bodoh, dan takut menunjukkan adanya kritik atau ketidaksetujuan yang disampaikan.\n",
        "-  kata-kata seperti menang, suka, bagus, amin, bijak, dan kasih menunjukkan dukungan terhadap program ini.\n",
        "- kata-kata gaji, gerung, perintah, tindak, umur, menunjukkan bahwa sebagian komentar netral membahas isu (misalnya aspek pendidikan, tokoh, atau kebijakan), bukan emosi pribadi.\n",
        "- Sentimen netral menujukkan beragamnya komentar wargenet terhadap program ini, baik pro dan kontra, tanpa ekspresi emosional yang kuat."
      ],
      "metadata": {
        "id": "36ZZ_XPoFLb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung total komentar per video\n",
        "total_per_video = data['video_title'].value_counts().reset_index(name='total_komentar')\n",
        "total_per_video.columns = ['video_title', 'total_komentar']\n",
        "\n",
        "# Hitung komentar netral per video\n",
        "netral_per_video = netral_data['video_title'].value_counts().reset_index(name='komentar_netral')\n",
        "netral_per_video.columns = ['video_title', 'komentar_netral']\n",
        "\n",
        "# Gabungkan berdasarkan video_title\n",
        "summary = pd.merge(netral_per_video, total_per_video, on='video_title')\n",
        "\n",
        "# Hitung rasio komentar netral\n",
        "summary['rasio_netral'] = summary['komentar_netral'] / summary['total_komentar']\n",
        "\n",
        "# Tampilkan top 10 video dengan rasio netral tertinggi\n",
        "summary.sort_values('rasio_netral', ascending=False).head(10)"
      ],
      "metadata": {
        "id": "E-g6s8scFIYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Video berjudul “Khofifah Tidak Setuju Siswa Nakal Dibawa ke Barak Militer”, “Akibat Bolos Sekolah Langsung Di Jemput…”, \"Akibat Bolos Sekolah Langsung Di Jemput Pak Dedi Mulyadi Masuk Barak Militer Di Roblox\"  memiliki rasio netral > 85%, menunjukkan bahwa topik-topik yang menyangkut otoritas atau tokoh besar sering mengundang komentar berhati-hati (netral) dan diluar topik isu program ini.\n",
        "- Video seperti “Dedi Mulyadi Balas Kritikan Rocky Gerung…” juga banyak memuat komentar netral, yang mungkin muncul dari penonton yang bingung atau tidak memihak dalam debat antar tokoh."
      ],
      "metadata": {
        "id": "YccufqyOFQJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topik Modelling"
      ],
      "metadata": {
        "id": "1lefzuqbFUd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertopic"
      ],
      "metadata": {
        "id": "_NAv2Cr0FIer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic"
      ],
      "metadata": {
        "id": "yXXKthQnFujL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentimen Positif"
      ],
      "metadata": {
        "id": "qKfXuPgkFmc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pos = data[data['label'] == 1]\n",
        "texts = text_pos['no_stopwords2']\n",
        "texts"
      ],
      "metadata": {
        "id": "SGebyZSzFlnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = texts.astype(str).tolist()"
      ],
      "metadata": {
        "id": "z4Log6eTFxX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install UMAP if not already installed\n",
        "!pip install umap-learn\n",
        "!pip install hdbscan # Install hdbscan library\n",
        "\n",
        "# Import UMAP\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN # Import HDBSCAN"
      ],
      "metadata": {
        "id": "4jiggYItbQgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi model UMAP dengan random_state\n",
        "umap_model = UMAP(n_neighbors=15,\n",
        "                  n_components=5,\n",
        "                  min_dist=0.0,\n",
        "                  metric='cosine',\n",
        "                  random_state=37)\n",
        "\n",
        "# Inisialisasi model clustering HDBSCAN dengan random_state\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=10,\n",
        "                        metric='euclidean',\n",
        "                        cluster_selection_method='eom',\n",
        "                        prediction_data=True)\n",
        "\n",
        "# Inisialisasi BERTopic dengan model yang sudah disetel random_state\n",
        "topic_model = BERTopic(\n",
        "    language=\"indonesian\",\n",
        "    calculate_probabilities=True,\n",
        "    umap_model=umap_model,\n",
        "    hdbscan_model=hdbscan_model,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Fit model\n",
        "topics, probs = topic_model.fit_transform(texts)\n",
        "\n",
        "# Tampilkan topik dominan\n",
        "topic_model.get_topic_info()"
      ],
      "metadata": {
        "id": "PKiwD2I0Rc5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_topics()"
      ],
      "metadata": {
        "id": "kMytsySCF2oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic modeling dilakukan pada komentar bersentimen positif dan menghasilkan lebih dari 60 topik. Namun, setelah dilakukan seleksi dan pengelompokan berdasarkan kesesuaian makna dan konteks, kami menyederhanakannya menjadi beberapa klaster utama saja.\n",
        "\n",
        "**Klaster 1: Religiusitas dan Spiritual**\n",
        "*   **Kata kunci:** *masyallah, subhanallah, tabarakallah, amin, amanah, rabbal, organisasi, produktif, berkat*\n",
        "*   **Interpretasi:** Klaster ini mencerminkan ekspresi keagamaan dan juga spiritualitas. Adanya kata-kata *masyallah* dan *subhanallah* menunjukkan kekaguman dan pujian terhadap program ini. Kata *amanah* dan *berkat* menunjukkan harapan bahwa program ini akan membawa kebaikan dan nilai moral.\n",
        "\n",
        "**Klaster 2: Nasionalisme dan Politik**\n",
        "*   **Kata kunci:** *nasionalisme, politik, partai, demokrasi, protes, leadership, kritik, komen, komentator*\n",
        "*   **Interpretasi:** Klaster ini menunjukkan bahwa program barak militer memicu diskusi tentang nilai-nilai kebangsaan dan politik. Kata-kata seperti *nasionalisme* dan *demokrasi* menandakan bahwa program ini dilihat sebagai bagian dari upaya memperkuat identitas nasional. Kata *kritik* dan *komentator* menunjukkan adanya diskusi dan evaluasi terhadap implementasi program.\n",
        "\n",
        "**Klaster 3: Pendidikan dan Pelatihan Fisik**\n",
        "*   **Kata kunci:** *latih, fisik, adrenalin, seleksi, boarding, guru, kurikulum, kelas, mahal, proses*\n",
        "*   **Interpretasi:** Klaster ini fokus pada aspek bagaimana pendidikan dan pelatihan fisik pada program ini. Kata-kata seperti *latih* dan *fisik* menunjukkan bahwa program ini bisa dianggap sebagai sarana untuk membentuk kedisiplinan dan daya tahan fisik siswa. Kata *kurikulum* dan *kelas* juga menunjukkan adanya perbandinan dan perhatian terhadap bagaimana program pendidikan yang diterapkan.\n",
        "\n",
        "\n",
        "**Klaster 4: Motivasi dan Keberlanjutan Program**\n",
        "*   **Kata kunci:** *pindah, langkah, pantang, mundur, lanjutkan, jasmani, doa, rohani, iman, tulus*\n",
        "*   **Interpretasi:** Klaster ini menujukkan semangat, motivasi, dan harapan keberlanjutan dari program ini. Kata-kata seperti *pantang* dan *mundur* menunjukkan dorongan untuk keberlanjutan program ini.\n",
        "\n",
        "**Klaster 5: Ekspresi Positif dan Dukungan**\n",
        "*   **Kata kunci:** mantap, mantul, keren, betul, maju, seru, bijak, semangat, cerdas, jiwa, hidup\n",
        "*   **Interpretasi:** Klaster ini terdiri dari ekspresi positif dan dukungan terhadap program. Kata-kata seperti *mantap* dan *keren* menunjukkan antusiasme dan apresiasi dari masyarakat. Istilah *maju* dan *bijak* menandakan bahwa program ini dianggap sebagai langkah positif dalam membentuk karakter siswa.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OuKB1OWRvlpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentimen Negatif"
      ],
      "metadata": {
        "id": "MpAVw5k0F5B9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pos2 = data[data['label'] == 3]\n",
        "texts2 = text_pos2['no_stopwords2']\n",
        "texts2"
      ],
      "metadata": {
        "id": "BIW34dZaF7xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts2 = texts2.astype(str).tolist()"
      ],
      "metadata": {
        "id": "aTcD4nJ3F-0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model = BERTopic(language=\"indonesian\", calculate_probabilities=True)  # gunakan bahasa Indonesia\n",
        "topics, probs = topic_model.fit_transform(texts2)\n",
        "\n",
        "topic_model.get_topic_info()"
      ],
      "metadata": {
        "id": "bJdyIRnGRiCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_barchart(top_n_topics=3)"
      ],
      "metadata": {
        "id": "_OdvE88gGEAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentimen negatif hanya menghasilkan dua topik utama, yang mencerminkan bahwa jumlah warganet YouTube yang tidak setuju dengan program ini tergolong sedikit.\n",
        "\n",
        "**Topik 0**\n",
        "*   **Kata-kata utama:** *pesantren, garut, kecuali, bangga, bunyi*\n",
        "*   **Interpretasi:** Topik ini menunjukkan ketidaksetujuan, misalnya perbandingan program dengan nilai-nilai atau praktik di pesantren. Kata *kecuali* dan *bangga* bisa menunjukkan adanya sikap membandingkan atau mempertanyakan program. Komentar seperti ini cenderung menyampaikan kritik atau menyindir konteks budaya/agama yang dianggap tidak cocok.\n",
        "\n",
        "**Topik 1**\n",
        "*   **Kata-kata utama:** *berantas, jkn, keras, sisi, gaya*\n",
        "*   **Interpretasi:** Topik ini menunjukkan  penolakan terhadap pelaksanaan program ini. Kata *berantas* dan *keras* menunjukkan kekritisan terhadap program ini yang dianggap terlalu ekstrem. *Sisi* dan *gaya* menyiratkan kritik terhadap citra atau cara penyampaian program yang dinilai kurang tepat dari sudut pandang tertentu.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "30_CKV8B1N17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentimen Netral"
      ],
      "metadata": {
        "id": "osde4DdLGGlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pos3 = data[data['label'] == 2]\n",
        "texts3 = text_pos3['no_stopwords2']\n",
        "texts3"
      ],
      "metadata": {
        "id": "K4bO6VCZGJyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts3 = texts3.astype(str).tolist()"
      ],
      "metadata": {
        "id": "wOA2mSwcGLu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi model UMAP dengan random_state\n",
        "umap_model = UMAP(n_neighbors=15,\n",
        "                  n_components=5,\n",
        "                  min_dist=0.0,\n",
        "                  metric='cosine',\n",
        "                  random_state=37)\n",
        "\n",
        "# Inisialisasi model clustering HDBSCAN dengan random_state\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=10,\n",
        "                        metric='euclidean',\n",
        "                        cluster_selection_method='eom',\n",
        "                        prediction_data=True)\n",
        "\n",
        "# Inisialisasi BERTopic dengan model yang sudah disetel random_state\n",
        "topic_model3 = BERTopic(\n",
        "    language=\"indonesian\",\n",
        "    calculate_probabilities=True,\n",
        "    umap_model=umap_model,\n",
        "    hdbscan_model=hdbscan_model,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Fit model\n",
        "topics, probs = topic_model3.fit_transform(texts3)\n",
        "\n",
        "# Tampilkan topik dominan\n",
        "topic_model3.get_topic_info()"
      ],
      "metadata": {
        "id": "dBsy4hIBRmfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model3.visualize_topics()"
      ],
      "metadata": {
        "id": "TT7jN2WmGL-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Komentar dengan sentimen netral sangat beragam, baik yang pro dan kontra dan sering kali keluar dari konteks topik utama, sehingga cukup sulit untuk diinterpretasikan. Topic modeling terhadap komentar netral menghasilkan lebih dari 60 topik. Namun, setelah dilakukan proses seleksi dan pengelompokan berdasarkan makna dan konteks, kami menyederhanakannya menjadi beberapa klaster utama berikut:\n",
        "\n",
        "**Klaster 1: Wilayah dan Identitas Lokal**\n",
        "*   **Kata kunci:** *provinsi, kabupaten, kota, desa, bahasa, halus, nadhatul ulama, rocky*\n",
        "*   **Interpretasi:** Klaster ini menunjukkan perhatian terhadap identitas lokal dan nilai-nilai budaya.\n",
        "\n",
        "**Klaster 2: Ucapan Syukur**\n",
        "*   **Kata kunci:** *alhamdulillah, rezeki, limpah, mulia, amin, kasih, cinta, sayang, sosok, semangat, hidup, akhirat, doa*\n",
        "*   **Interpretasi:** Klaster ini menujukkan respons positif yang bersifat religius dan emosional. Komentar bernada doa, ucapan syukur, dan pujian terhadap tokoh atau program yang dianggap membawa kebaikan, baik secara spiritual maupun sosial.\n",
        "\n",
        "**Klaster 3: Isu Politik dan Pendidikan**\n",
        "*   **Kata kunci:** *politik, partai, demokrasi, juang, gerung, sarjana, akademisi, alumni*\n",
        "*   **Interpretasi:** Klaster ini menunjukkan komentar yang menyinggung aspek politik dan pendidikan, seperti partisipasi politik, kritik terhadap sistem, atau diskusi seputar latar belakang akademik tokoh yang dibahas.\n",
        "\n",
        "\n",
        "**Klaster 4: Relasi Keluarga dan Sosial**\n",
        "*   **Kata kunci:** *emaknya, emak, orangtua, hadir, kakak, perempuan, istri, cewek, beliau*\n",
        "*   **Interpretasi:** Klaster ini menampilkan komentar yang mengacu pada keluarga atau tokoh perempuan. Bisa bersifat netral, bercanda, atau menyindir, tergantung konteks kalimat. Kehadiran tokoh perempuan juga bisa menunjukkan stereotip sosial atau ekspresi identitas gender.\n",
        "\n",
        "\n",
        "\n",
        "**Klaster 5: Nada Negatif atau Ketidakpuasan Terselubung**\n",
        "*   **Kata kunci:** *bosan, minim, jarang, kosong, kapan (kapai), lupa, kalah, hilang, iri hati, odoh, sampah, mulut, sedih, jahat, toxic, obat, narkotika*\n",
        "*   **Interpretasi:** Meski bersentimen netral, klaster ini menunjukkan komentar yang mengandung ketidakpuasan atau kritik pasif-agresif. Isinya sering kali bersifat sindiran, ekspresi kejenuhan, atau kekecewaan yang tersamar.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7kWB1sDh6M7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Insight yang Didapat**"
      ],
      "metadata": {
        "id": "aUBVty8rWp48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan analisis percakapan warganet di media sosial, khususnya YouTube, ditemukan sejumlah pola dan temuan penting yang menggambarkan respons publik terhadap program barak militer bagi siswa bermasalah di Jawa Barat.\n",
        "\n",
        "1. **Tingginya Minat Publik di Media Sosial.**\n",
        "  \n",
        "  Hal tersebut tercermin dari lonjakan komentar pada 4 Mei dan 24 Mei 2025, yang menandakan bahwa isu ini mendapat respons besar dan memicu diskusi aktif di kalangan warganet, terutama di platform YouTube.\n",
        "2.**Proporsi Sentimen Mayoritas Netral dan Positif.**\n",
        "\n",
        "  Sentimen positif didominasi oleh dukungan terhadap program ini, terutama dalam nilai kedispilinan, nasionalisme, dan harapan terhadap perubahan perilaku siswa. Sementara itu, sentimen netral cenderung bersifat acak atau menunjukkan ketidakjelasan sikap publik terhadap isu ini.\n",
        "\n",
        "3. **Sentimen Negatif Sangat Rendah.**\n",
        "\n",
        "  Sentimen negatif bersifat preventif, yang isinya lebih banyak berupa kewaspadaan terhadap pendekatan kebijakan, bukan perlawanan terhadap tujuannya. Ini memberi peluang bagi pemerintah untuk membangun narasi kebijakan yang lebih edukatif dan empatik.\n",
        "4. **Judul-Judul Video Bersifat Provokatif dan Emosional.**\n",
        "\n",
        "  Banyaknya judul clickbait seperti \"Anak Nakal\", \"Setujukah kalian\", \"Sindir Elite\" mendorong warganet untuk berkomentar. Judul-judul dengan nada emosional terbukti sangat menarik perhatian dan respons dari warganet.\n",
        "\n",
        "5. **Tokoh Sangat Berpengaruh dalam Meningkatnya Perhatian Terhadap Isu Ini.**\n",
        "\n",
        "  Program ini tidak lepas dari peran Dedi Mulyadi sebagai Gubernur Jawa Barat sekaligus pengusung utama program. Banyak komentar yang muncul tidak hanya menilai program itu sendiri, tetapi juga menyoroti sosok Dedi Mulyadi, baik dalam bentuk dukungan maupun kritik.\n",
        "\n",
        "6. **Warganet Membandingkan Program Barak Militer dengan Pendidikan Karakter Lain.**\n",
        "\n",
        "  Sejumlah warganet membandingkan program ini dengan pendidikan karakter lain berbasis pesantren, psikologi, dan model pendidikan di negara komunis. Hal ini mencerminkan harapan publik terhadap hadirnya pendekatan pendidikan karakter yang lebih efektif dan sesuai"
      ],
      "metadata": {
        "id": "vIIeM0itRqsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rekomendasi**"
      ],
      "metadata": {
        "id": "cINAhSuJWzty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan temuan dan analisis percakapan warganet, rekomendasi berikut ditujukan kepada pemerintah daerah dan pihak terkait agar program barak militer ini dapat berjalan dengan lebih efektif, adil, dan mendapat dukungan publik yang luas.\n",
        "\n",
        "1. **Perlu Evaluasi Multidisipliner terhadap Program**\n",
        "\n",
        "  Perlunya evaluasi yang melibatkan psikolog, pendidik, dan pakar hak anak untuk merancang pendekatan yang lebih dekat dengan sosial.\n",
        "\n",
        "2. **Transparansi dan Sosialisasi Program**\n",
        "\n",
        "  Harus adanya transparansi dan sosialisasi program. Narasi resmi dan penjelasan detail perlu disampaikan secara terbuka, terutama lewat platform yang ramai diskusi seperti YouTube dan Instagram.\n",
        "\n",
        "3. **Narasi Positif tanpa Provokasi Emosional**\n",
        "\n",
        "  Kurangi penggunaan istilah atau visual yang mengesankan hukuman atau kekarasan dalam publikasi. Fokus pada narasi pembinaan, karakter, dan kesempatan kedua.\n",
        "\n",
        "4. **Pertimbangkan Alternatif Non-Militeristik**\n",
        "\n",
        "  Pertimbangkan alternarif dari program ini (non militeristik), banyak komentar apresiasi terhadap pesantren dan pendekatan psikologis. Ini dapat diitegrasikan sebagai opsi alternatif.\n",
        "\n",
        "\n",
        "5. **Lakukan Monitoring dan Feedback Berkala**\n",
        "\n",
        "  Dilakukan monitoring dan feedback berkala untuk menunjukkan akuntabilitas dan keterbukaan pemerintah terhadap program ini."
      ],
      "metadata": {
        "id": "HqHs8C4zR2Tu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Kesimpulan**"
      ],
      "metadata": {
        "id": "WTN6sSVuWD48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Banyak warganet mendukung program barak militer bagi siswa bermasalah di Jawa Barat sebagai upaya membentuk karakter dan kedisiplinan. Sedangkan, hanya sedikit warganet yang menentang program ini, menurut mereka pendekatan disiplin ala militer yang dinilai sebagian pihak terlalu keras dan berisiko melanggar hak anak. Pola percakapan warganet di YouTube menunjukkan tingginya atensi publik, dengan komentar yang mencerminkan keresahan, dukungan, dan refleksi terhadap peran orang tua serta sekolah. Sosok Dedi Mulyadi sebagai penggagas program dipandang cukup positif, dianggap tegas, berani, dan peduli terhadap masalah sosial, meskipun tidak lepas dari kontroversi."
      ],
      "metadata": {
        "id": "V-0LEB0vWF7u"
      }
    }
  ]
}